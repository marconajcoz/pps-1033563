# 5.1 Instalaci√≥n y Despliegue de K3s y visi√≥n con K9S (Modo Single-Node) üöÄüêß

En esta gu√≠a vamos a instalar **K3s**, una versi√≥n ligera y simplificada de Kubernetes, en modo *single-node* sobre Linux Mint. Despu√©s desplegaremos un servicio NGINX con dos r√©plicas y validaremos todo con la herramienta visual **K9s**, que facilita la gesti√≥n de cl√∫steres Kubernetes desde la terminal.

---

## 1. Instalaci√≥n de K3s ‚öôÔ∏è

Para instalar K3s utilizamos el script oficial proporcionado por Rancher Labs. Este script descarga e instala el binario, configura los servicios necesarios y levanta el cl√∫ster autom√°ticamente. De esta forma, evitamos pasos manuales complejos y conseguimos un cl√∫ster Kubernetes funcional en pocos minutos.

---
 
![K3S](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/1-InstalarK3S.PNG)

---

## 2. Verificaci√≥n del estado del servicio ‚úÖ

Una vez instalado, comprobamos que el servicio de K3s est√© corriendo correctamente. Esto se hace consultando el estado del servicio mediante el sistema de init de Linux. Si todo est√° bien, el estado aparecer√° como activo y en ejecuci√≥n, lo que significa que el cl√∫ster est√° listo para usarse.

---

![K3S Status](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/2-StatusK3S.PNG)

---

## 3. Uso de `kubectl` para administrar el cl√∫ster üñ•Ô∏è

K3s incluye su propia versi√≥n integrada de `kubectl`, la herramienta oficial para gestionar Kubernetes. Con ella podemos interactuar con el cl√∫ster, listar nodos, desplegar aplicaciones, revisar pods, servicios y m√°s.

Por ejemplo, para listar los nodos y verificar que nuestro nodo est√° en estado **Ready**, ejecutamos el comando correspondiente.

---

![K3S Nodos](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/3-NodoListo.PNG)

---

Opcionalmente, podemos configurar el entorno para usar `kubectl` sin necesidad de anteponer `sudo` ni usar el binario propio de K3s. Para ello, copiamos el archivo de configuraci√≥n a nuestro usuario y creamos un enlace simb√≥lico. Esto facilita el uso de Kubernetes a futuro.

---

## 4. Despliegue de un servicio NGINX con dos r√©plicas üê≥

Para probar el cl√∫ster, creamos un archivo [YAML que define un despliegue de NGINX](https://github.com/marconajcoz/pps-1033563/blob/main/RA5/RA5_4/assets/code/nginx-deployment.yaml) accesible en /assets/code de este repositorio con dos r√©plicas y un servicio tipo LoadBalancer para exponerlo. Este despliegue har√° que dos contenedores NGINX est√©n corriendo en paralelo dentro del cl√∫ster.

Luego aplicamos esta configuraci√≥n para que Kubernetes cree los pods y el servicio.

---

![Nginx Deploy](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/4-AplicarNginxDeploy.PNG)

---

## 5. Validaci√≥n de los pods y servicios en ejecuci√≥n üîç

Es fundamental verificar que los pods se est√©n ejecutando correctamente y que el servicio est√© activo. Con comandos simples podemos listar todos los pods para confirmar su estado y tambi√©n ver los servicios disponibles para asegurarnos de que NGINX est√° expuesto y accesible.

---

![Pods K3S](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/5-ComprobarNodos.PNG)

---

## 6. Gesti√≥n visual con K9s üéõÔ∏è

Para facilitar la administraci√≥n del cl√∫ster, podemos usar **K9s**, una herramienta que muestra una interfaz amigable en la terminal para visualizar recursos, logs y estados del cl√∫ster en tiempo real.

Una vez instalado, simplemente lanzamos `k9s` y podremos navegar por todos los recursos con facilidad, haciendo mucho m√°s c√≥moda la gesti√≥n.

---

![K9S Funciona](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/7-NodosDesdeK9S.PNG)

---

Con estos pasos tendr√°s un cl√∫ster K3s operativo en modo single-node, un servicio NGINX desplegado con r√©plicas y una forma eficiente de gestionar todo a trav√©s de K9s.

# 5.2 Instalaci√≥n y Despliegue de K3s y visi√≥n con K9S (Modo HA) üöÄüêß

## üöÄ Introducci√≥n

Kubernetes es una plataforma de orquestaci√≥n de contenedores que automatiza la implementaci√≥n, escalado y gesti√≥n de aplicaciones en contenedores. Una de sus capacidades m√°s importantes es la alta disponibilidad (HA), que permite mantener las aplicaciones funcionando incluso si uno o varios nodos del cl√∫ster fallan.

En esta pr√°ctica se ha desplegado un cl√∫ster Kubernetes en alta disponibilidad usando K3s, una distribuci√≥n ligera y certificada de Kubernetes dise√±ada para entornos con recursos limitados, pero con todas las funcionalidades esenciales.

## üíª Entorno utilizado

Se han empleado tres servidores con Ubuntu Server 24.04, configurados para formar un cl√∫ster K3s en alta disponibilidad. Los nodos se identifican como master1k3s, master2k3s y master3k3s.  

Cada nodo est√° configurado para que el primero (master1k3s) act√∫e como nodo principal (control-plane), y los otros dos se unan al cl√∫ster utilizando el token generado por el primero.

---

## üõ†Ô∏è Pasos realizados

### 1Ô∏è‚É£ Instalaci√≥n en master1k3s y obtenci√≥n del token

En el nodo master1k3s se instal√≥ K3s como nodo principal. Tras la instalaci√≥n, se extrajo el token necesario para que los dem√°s nodos puedan unirse al cl√∫ster con alta disponibilidad. Este token permite autenticar y conectar de forma segura los nodos adicionales.

![K3S Master1](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/8-InstalarK3SAltaDisp.PNG)

### 2Ô∏è‚É£ Instalaci√≥n en master2k3s y master3k3s con referencia al token de master1k3s

En los nodos master2k3s y master3k3s se instal√≥ K3s como nodos adicionales, especificando durante la instalaci√≥n el token obtenido de master1k3s y la IP del nodo principal. Esto hizo posible la uni√≥n de los nodos al cl√∫ster, configurando as√≠ un entorno con m√∫ltiples nodos que ofrecen resiliencia y balanceo de carga para los componentes de control.

![K3S Master2](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/9-InstalarK3SyLinkMast1EnMast2.PNG)

![K3S Master3](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/10-InstalarK3SyLinkMast1EnMast3.PNG)

### 3Ô∏è‚É£ Verificaci√≥n del cl√∫ster con `kubectl get nodes`

Desde cualquiera de los nodos con la configuraci√≥n correcta del fichero kubeconfig, se ejecut√≥ el comando para listar los nodos del cl√∫ster. Se pudo comprobar que los tres nodos aparecen como listos (`Ready`), donde master1k3s figura con el rol de `control-plane,etcd,master` y master2k3s y master3k3s aparecen con estado listo pero sin roles expl√≠citos de control-plane, lo cual es correcto para un cl√∫ster K3s configurado para HA.

![Nodos](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/11-3Nodos.PNG)

### 4Ô∏è‚É£ Creaci√≥n y despliegue de nginx-deployment

Se cre√≥ un fichero [nginx-deployment.yaml](https://github.com/marconajcoz/pps-1033563/blob/main/RA5/RA5_4/assets/code/nginx-deployment.yaml) que define un despliegue con varias r√©plicas del servidor web Nginx. Con el comando `kubectl apply -f nginx-deployment.yaml` se aplic√≥ esta configuraci√≥n al cl√∫ster, creando el deployment y el servicio asociado.

![Aplicar Nginx](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/12-AplicarNginxMaster1.PNG)

### 5Ô∏è‚É£ Comprobaci√≥n de los pods y servicios

Se verific√≥ que los pods del despliegue de Nginx se estaban ejecutando correctamente usando `kubectl get pods`. Se observaron dos r√©plicas, ambas en estado `Running`, distribuidas en dos nodos distintos (master2k3s y master3k3s). Esto indica que el cl√∫ster est√° gestionando el despliegue de forma distribuida.

El servicio asociado se cre√≥ como tipo `LoadBalancer` con un puerto expuesto, aunque en un entorno local el EXTERNAL-IP aparece como `<pending>`, esto es esperado si no hay un controlador externo que asigne IPs p√∫blicas.

![Pods y SVC](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/13-PodsYSVCMaster1.PNG)

### 6Ô∏è‚É£ Prueba de acceso con curl a Nginx

Se realiz√≥ una consulta HTTP directa al puerto del servicio expuesto (por ejemplo, en la IP 192.168.1.121 con puerto 31002), y se recibi√≥ la p√°gina est√°ndar de bienvenida de Nginx. Esto confirma que el servidor web est√° corriendo correctamente dentro del cl√∫ster y es accesible desde la red.

![Curl Nginx](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/14-NginxFunciona.PNG)

### 7Ô∏è‚É£ Monitorizaci√≥n visual con K9s

Finalmente, se utiliz√≥ la herramienta K9s para visualizar el estado del cl√∫ster de manera interactiva. En K9s se pudieron observar los pods desplegados, sus estados, nodos en los que se ejecutan, consumo de recursos y m√°s. La visualizaci√≥n confirma que las r√©plicas de nginx est√°n distribuidas en nodos diferentes, reforzando la arquitectura de alta disponibilidad.

![K9S](https://github.com/marconajcoz/pps-1033563/raw/main/RA5/RA5_4/assets/images/15-HAConseguidaK9S.PNG)
